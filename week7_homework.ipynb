{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a dataset (X) and corresponding labels (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict probabilities on the test set\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 4: Try different thresholds and evaluate the impact on metrics\n",
    "thresholds = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    predictions = (probs >= threshold).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\\n\")\n",
    "\n",
    "# Step 5: Fit a Logistic Regression Model on all features\n",
    "model_all_features = LogisticRegression()\n",
    "model_all_features.fit(X, y)\n",
    "\n",
    "# Step 6: Plot ROC Curve for both models\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, probs)\n",
    "roc_auc = roc_auc_score(y_test, probs)\n",
    "\n",
    "fpr_all, tpr_all, thresholds_roc_all = roc_curve(y, model_all_features.predict_proba(X)[:, 1])\n",
    "roc_auc_all = roc_auc_score(y, model_all_features.predict_proba(X)[:, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {roc_auc:.2f})')\n",
    "plt.plot(fpr_all, tpr_all, label=f'Logistic Regression (All Features) (AUC = {roc_auc_all:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a dataset (X)\n",
    "\n",
    "# Step 1: Varying k and analyzing inertia and silhouette scores\n",
    "k_values = [2, 3, 4, 5, 6]\n",
    "\n",
    "for k in k_values:\n",
    "    # Perform k-means clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Inertia: Sum of squared distances of samples to their closest cluster center\n",
    "    inertia = kmeans.inertia_\n",
    "\n",
    "    # Silhouette Score\n",
    "    silhouette_avg = silhouette_score(X, kmeans.labels_)\n",
    "\n",
    "    print(f\"Number of Clusters (k): {k}\")\n",
    "    print(f\"Inertia: {inertia:.4f}, Silhouette Score: {silhouette_avg:.4f}\\n\")\n",
    "\n",
    "# Step 2: Analyzing the impact of not scaling features\n",
    "kmeans_unscaled = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans_unscaled.fit(X)\n",
    "\n",
    "inertia_unscaled = kmeans_unscaled.inertia_\n",
    "silhouette_unscaled = silhouette_score(X, kmeans_unscaled.labels_)\n",
    "\n",
    "print(\"Without Scaling Features:\")\n",
    "print(f\"Inertia: {inertia_unscaled:.4f}, Silhouette Score: {silhouette_unscaled:.4f}\\n\")\n",
    "\n",
    "# Step 3: Discussing the concept of the 'right' k\n",
    "# You can use various methods like the elbow method, silhouette analysis, or cross-validation\n",
    "# to find an optimal value for k. There is no one \"right\" k, and it depends on the specific data and problem.\n",
    "\n",
    "# Example: Elbow Method\n",
    "inertia_values = []\n",
    "for k in range(1, 11):\n",
    "    kmeans_elbow = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans_elbow.fit(X)\n",
    "    inertia_values.append(kmeans_elbow.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), inertia_values, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
